Awesome‚Äîhere‚Äôs a single, master playbook that covers both phases in one place, with step-by-step tasks you can follow in sequence to ship the chatbot (Phase 1) and then extend it to agent actions (Phase 2). Save it as DETAILED_BUILD_TASKS_WITH_PHASES.md.


---

# üß± Detailed Build Tasks (with Phases)
## AI Onboarding & Workplace Assistant ‚Äî End-to-End Implementation Guide
**Owner:** Tibbi Labs ‚Ä¢ **Version:** v1.0 ‚Ä¢ **Last Updated:** Oct 2025

> This is your single source of truth to build the product from code-zero to production for **Phase 1 (Chatbot)** and **Phase 2 (Agent Mode)**.  
> Assumption: AWS account(s), Terraform, VCS, and Bedrock access are already set up.

---

## üìå Roadmap at a Glance

| Phase | Goal | Duration | Exit Criteria |
|---|---|---|---|
| **Phase 1 ‚Äì Chatbot (Q&A)** | Google Chat ‚Üí Lambda ‚Üí Bedrock KB grounded answers | ~6 weeks | Accuracy ‚â• 90%, unsafe ‚â§ 0.5%, p95 ‚â§ 2s, UAT pass |
| **Phase 2 ‚Äì Agent Mode (Actions)** | Bedrock Agent tools ‚Üí Lambda actions (SailPoint/HRMS etc.) | ~8 weeks | Tool success ‚â• 99%, approvals enforced, immutable audit, kill-switch verified |

---

# PHASE 1 ‚Äî Conversational Chatbot (Q&A)

## 1. Google Chat App & Webhook

**Tasks**
1. Create Chat app (DM-only). Set **App URL** to your API Gateway endpoint.
2. Enforce signed webhooks; store Google signing secret in **Secrets Manager**.
3. Whitelist org users (optional) and disable Spaces for now.
4. Smoke test: send ‚Äúhello‚Äù ‚Üí confirm Lambda is invoked and returns 200.

**Deliverables**
- Registered Chat app
- Verified webhook connectivity

---

## 2. Lambda Application (`chat-webhook`) & Routing

**Code Layout**

/lambda ‚îú‚îÄ‚îÄ chat-webhook.py ‚îú‚îÄ‚îÄ requirements.txt ‚îî‚îÄ‚îÄ utils/ ‚îú‚îÄ‚îÄ google_auth.py ‚îú‚îÄ‚îÄ bedrock_client.py ‚îú‚îÄ‚îÄ formatter.py ‚îî‚îÄ‚îÄ logger.py

**Tasks**
1. Parse webhook payload (userId, message, threadId).  
2. Verify signature (utils/google_auth.py).  
3. Fetch minimal user context from DynamoDB (`user_profile`: role, region).  
4. Build **PII-minimized** prompt; call Bedrock Converse ‚Üí KB.  
5. Format response for Google Chat (markdown/card + üëç/üëé buttons).  
6. Log to DynamoDB (`chat_logs`): {user, text, answer, sources, latency, feedback=null}.  
7. Return 200 with JSON card.

**Acceptance**
- Round-trip latency ‚â§ 2s (p95), correct formatting in Chat.

---

## 3. Knowledge Base (DocOps) Integration

**S3 + Bedrock KB**
- S3 bucket (versioned): `kb-company-docs/` (docs, runbooks, policies).
- Bedrock KB with S3 data source; Titan Embeddings (text) or managed embeddings.

**Sync**
- GitHub Action ‚Üí `aws s3 sync docs/ s3://kb-company-docs/docs/ --delete`
- Post-sync: `bedrock start-ingestion-job` (data source IDs via repo secrets).

**Governance**
- Content review before sync; tag docs with `{dept, region, sensitivity, owner, version}`.

**Acceptance**
- Queries like ‚ÄúWhat do I do on Day 1?‚Äù return grounded answers w/ references.

---

## 4. Data Layer (DynamoDB)

**Tables**
- `user_profile` (pk=`USER#{id}`): role, dept, region
- `chat_logs` (pk=`LOG#{uuid}`): request/response metadata (TTL 90d)
- `chat_threads` (pk=`THREAD#{chatThreadId}`): optional thread‚Üíuser map (TTL 7d)

**IAM**
- Lambda policy: least-privilege for GetItem/PutItem on these tables.

---

## 5. Security & Guardrails (Phase 1)

**Controls**
- Bedrock Guardrails: PII redaction, toxicity, deny lists
- Prompt hardening: refuse secrets, internal IDs, or tool calls (Phase 1 has no tools)
- TLS 1.2+, KMS on S3/DDB/Secrets; no secrets in logs

**Kill-Switch (Phase 1)**
- Feature flag `ENABLE_CHATBOT` (SSM Parameter) checked in handler

---

## 6. Observability & Cost

**Dashboards**
- Lambda latency/errors/throttles
- Bedrock token usage & guardrail triggers
- DDB write throughput
- Cost per 1k Q&A

**Alarms**
- p95 latency > 2.5s for 5m
- Guardrail triggers spike > baseline
- 5xx from API Gateway > 1%

---

## 7. Testing & UAT

**Test Types**
- Unit: payload parsing, signature verify, formatter
- Integration: Chat ‚Üí API GW ‚Üí Lambda ‚Üí Bedrock ‚Üí KB
- Performance: 100 concurrent messages
- Safety: prompt injection, PII bait, policy violations
- UAT: HR/IT scripted flows (‚â•100 Q&A pairs)

**Exit Criteria**
- Accuracy ‚â• 90%, unsafe ‚â§ 0.5%, p95 ‚â§ 2s, CSAT ‚â• 4.5/5

---

## 8. Launch Runbook (Phase 1)

1. Enable Guardrails & flags; verify dashboard.
2. Roll out to pilot OU (HR+IT).
3. Announce bot + quickstart guide.
4. Monitor 1 week; capture feedback; tune prompt/KB.

---

# PHASE 2 ‚Äî Agent Mode (Actions)

> Build on Phase 1. Keep the same webhook Lambda, add **Agent tools** and **Action Lambdas** behind strict policy gates and audits. MCP is optional and can be added behind a Lambda router.

## 9. Action Surface & Contracts

**Initial Tools (examples)**
- `submit_access_request(app, role?, justification?)`
- `get_access_status(requestId)`
- `list_my_access()`

**OpenAPI (Action Group) ‚Äî Sketch**
```yaml
openapi: 3.0.1
info: { title: Access Tools, version: 1.0.0 }
paths:
  /submit_access_request:
    post:
      operationId: submit_access_request
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: [app]
              properties:
                app: { type: string, minLength: 2, maxLength: 64 }
                role: { type: string, maxLength: 64 }
                justification: { type: string, maxLength: 512 }
      responses: { "200": { description: OK } }
  /get_access_status:
    post:
      operationId: get_access_status
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required: [requestId]
              properties:
                requestId: { type: string, pattern: "^[A-Za-z0-9-]{6,64}$" }
      responses: { "200": { description: OK } }
  /list_my_access:
    post:
      operationId: list_my_access
      responses: { "200": { description: OK } }

JSON Schema Validation (server-side too)

Validate strings, lengths, enums, and patterns.

Reject unknown fields; sanitize justification text.



---

10. Lambda Tooling & RBAC

Lambdas

access-submit ‚Üí create request in SailPoint/Okta/Jira

access-status ‚Üí poll status

access-list ‚Üí list current entitlements


Server-Side Enforcement

1. AuthN: map Chat user ‚Üí employeeId (Phase 1 mapping)


2. RBAC/ABAC: self-service only unless caller.isManager == true


3. Policy checks: per-app allow list, role templates


4. Idempotency: Idempotency-Key: {userId}:{app}:{role}


5. Audit: write append-only record {who, what, when, inputs(hash), result, correlationId}



Secrets

OAuth creds in Secrets Manager with rotation policy



---

11. Orchestration: Bedrock Agent + Action Groups

Tasks

1. Create Bedrock Agent with Phase-2 system prompt (ask for missing parameters, confirm risky actions).


2. Register Action Group using OpenAPI above, mapping operations to your Lambdas (via API GW).


3. Add tool-usage policy in the Agent prompt (never invent data; always return requestId).



Go/No-Go Gate

Tools enabled only in stage first; feature flag per tool (ENABLE_TOOL_SUBMIT, etc.)



---

12. Optional MCP Bridge (Later)

Design

Keep current Lambdas; optionally add an MCP client inside a ‚Äúrouter‚Äù Lambda that forwards tool calls to an MCP server for SailPoint, Jira, etc.

This keeps your Agent ‚Üí Action Group contract stable while letting you standardize integrations.



---

13. Step Functions (If Multi-Step Approvals)

When to use

Multi-stage access (manager ‚Üí app owner ‚Üí provisioning)

Long-running ops (SLA minutes/hours)


Pattern

Agent calls orchestrate_onboarding tool ‚Üí Step Functions workflow ‚Üí posts status updates to Chat via webhook Lambda.



---

14. Security Hardening (Phase 2)

Additions

Human-in-the-loop confirmations for high-risk actions

Kill-switch per tool (SSM Parameter Store)

Deny-by-default tool allow-list

Egress control: only approved API endpoints via VPC endpoints or NAT policy

Input scrubbing: strip prompts attempting to coerce tool behavior

Red-team: run tool abuse & data exfil drills



---

15. Observability for Actions

Dashboards

Tool call success rate, error/category (4xx validation vs 5xx upstream)

Time-to-provision per app

Pending vs completed requests

Anomaly alerts: spikes in rejected actions, repeated failed attempts


Trace IDs

Propagate correlationId from Chat ‚Üí Agent ‚Üí Tool Lambda ‚Üí Upstream system



---

16. Phase 2 Testing

What to test

Contract validation (bad inputs rejected)

RBAC (non-manager cannot act for others)

Idempotency (duplicate submit generates one request)

Tool misuse (prompt injection to bypass approvals)

Latency budget: tool calls within SLO or gracefully degrade


Exit Criteria

Tool success ‚â• 99%

0 policy bypasses; audit trail complete

Manager approval flow verified end-to-end

Kill-switch disables tools within 1 minute



---

17. Rollout Strategy (Phase 2)

1. Dark launch: tools deployed but disabled by flag


2. Canary: enable for security/IT admins only


3. Pilot: enable for one BU/region


4. Org-wide: staged expansion with dashboards/alerts green




---

18. RACI (Phases 1 & 2)

Area	Responsible	Accountable	Consulted	Informed

Chat Lambda	Backend	AI Lead	Security	Product
Bedrock KB	AI	AI Lead	HR/IT	Product
Guardrails	Security	CISO	AI	All
Action Lambdas	Backend	Platform Eng	Security, App Owners	Product
Approvals & RBAC	Security	CISO	HR/IT	All
Observability	DevOps	Platform Eng	Security	All
UAT & Launch	Product	Product	HR/IT, Security	All



---

19. Deliverables (Checklist)

Phase 1

[ ] Google Chat app (DM-only), signed webhooks

[ ] chat-webhook Lambda + tests

[ ] Bedrock KB (S3 source) + Guardrails

[ ] GitHub‚ÜíS3 sync workflow + KB ingestion

[ ] DDB tables (user_profile, chat_logs, chat_threads)

[ ] CloudWatch dashboards + alarms

[ ] UAT report (accuracy/safety/latency)


Phase 2

[ ] OpenAPI spec (tools)

[ ] Action Lambdas (access-submit, access-status, access-list)

[ ] Bedrock Agent + Action Group wiring

[ ] RBAC policy engine + approvals (if needed)

[ ] Immutable audit stream

[ ] Kill-switch flags per tool

[ ] Red-team & tool-abuse report



---

20. Definition of Done (Per Phase)

Phase 1 DoD

‚úÖ Grounded Q&A with source references

‚úÖ Safety guardrails block unsafe content

‚úÖ Observability and cost dashboards in place

‚úÖ UAT passed; pilot users satisfied (CSAT ‚â• 4.5/5)


Phase 2 DoD

‚úÖ Tools operate within RBAC & approvals

‚úÖ Full audit trail & idempotency enforced

‚úÖ Canary + pilot successful; no policy bypasses

‚úÖ Kill-switch validated; playbooks updated



---

21. Risk Register (Top-5)

Risk	Phase	Impact	Mitigation

Prompt injection	1 & 2	High	Guardrails, input scrubbing, tests
Hallucinations	1	Med	RAG + sources, accuracy evals
Tool misuse	2	High	RBAC, approvals, deny-by-default
Cost spikes	1 & 2	Med	Token trimming, dashboards, budgets
Outdated KB	1	Med	Pre-publish review + frequent sync



---

22. Appendices

A. Example Prompt Snippets (Phase 1)

System: ‚ÄúYou are a safe workplace assistant. Use only provided documents; if unknown, say you don‚Äôt know. Never perform actions.‚Äù

User template: includes role & region tags only (no raw PII)


B. Example Confirmation UX (Phase 2)

Bot: ‚ÄúYou‚Äôre requesting VPN access for yourself with role Employee. Proceed?‚Äù

User: ‚ÄúYes‚Äù

Bot: ‚ÄúRequest submitted ‚úÖ REQ-12345. I‚Äôll update you on status.‚Äù


C. Rollback Playbook

Disable tools via SSM flag

Revert Agent to Chat-only prompt

Freeze KB ingestion if suspected content issue

Rotate affected secrets



---

This document is the step-by-step manual to deliver both phases safely and predictably. Follow Phase 1 first; after stabilization, proceed to Phase 2 using the same repo and CI/CD patterns.

If you want, I can also generate **starter code** for `chat-webhook.py` and the **OpenAPI + JSON Schemas** for Phase-2 tools so your team can start committing right away.Ó®Å0Ó®Ç

